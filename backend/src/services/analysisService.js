import OpenAI from 'openai';

// Initialize OpenAI client lazily
let openaiClient = null;

const getOpenAIClient = () => {
  if (!openaiClient) {
    if (!process.env.OPENAI_API_KEY) {
      throw new Error('OPENAI_API_KEY environment variable is not set');
    }
    openaiClient = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
    });
  }
  return openaiClient;
};

// Analysis prompts optimized for OpenAI
const ANALYSIS_PROMPTS = {
  sentiment: `Analyze the sentiment of this text and respond with ONLY a JSON object in this exact format:
{
  "sentiment": <number between -1 and 1>,
  "confidence": <number between 0 and 1>,
  "reasoning": "<brief explanation>"
}

Text to analyze: "{text}"`,

  toxicity: `Analyze the toxicity level of this text and respond with ONLY a JSON object in this exact format:
{
  "toxicity": <number between 0 and 1>,
  "categories": ["<list of relevant categories like harassment, hate_speech, insults, etc>"],
  "reasoning": "<brief explanation>"
}

Text to analyze: "{text}"`,

  engagement: `Analyze the engagement potential of this text and respond with ONLY a JSON object in this exact format:
{
  "engagement": <number between 0 and 1>,
  "type": "<question, discussion, announcement, or general>",
  "reasoning": "<brief explanation>"
}

Text to analyze: "{text}"`,

  ai_detection: `Determine if this text was likely generated by AI and respond with ONLY a JSON object in this exact format:
{
  "ai_likelihood": <number between 0 and 1>,
  "indicators": ["<list of AI indicators found>"],
  "reasoning": "<brief explanation>"
}

Text to analyze: "{text}"`,

  quality: `Assess the quality and constructiveness of this text and respond with ONLY a JSON object in this exact format:
{
  "quality_score": <number between 0 and 1>,
  "constructiveness": <number between 0 and 1>,
  "indicators": ["<list of quality indicators>"],
  "reasoning": "<brief explanation>"
}

Text to analyze: "{text}"`,

  community_health: `Analyze the overall health of this community based on these messages and respond with ONLY a JSON object in this exact format:
{
  "health_score": <number between 0 and 1>,
  "positive_indicators": ["<list of positive aspects>"],
  "concerns": ["<list of concerns>"],
  "recommendations": ["<list of improvement suggestions>"]
}

Messages:
{messages}`
};

class AnalysisService {
  constructor() {
    this.isInitialized = false;
    this.client = null;
    this.model = process.env.OPENAI_MODEL || 'gpt-4.1-nano-2025-04-14';
    this.maxRetries = 3;
    this.retryDelay = 1000;
  }

  async initClient() {
    try {
      this.client = getOpenAIClient();
      this.isInitialized = true;
      console.log(`‚úÖ OpenAI API initialized successfully (model: ${this.model})`);
    } catch (error) {
      console.error('‚ùå Error initializing OpenAI API:', error);
      this.isInitialized = false;
    }
  }

  async analyzeMessage(messageText, analysisType = 'sentiment') {
    if (!this.isInitialized) {
      await this.initClient();
    }

    if (!this.client || !this.isInitialized) {
      console.warn('OpenAI API not available, using fallback analysis');
      return this.createFallbackAnalysis(messageText, analysisType);
    }

    try {
      const prompt = ANALYSIS_PROMPTS[analysisType]?.replace('{text}', messageText);
      if (!prompt) {
        throw new Error(`Unknown analysis type: ${analysisType}`);
      }

      const completion = await this.client.chat.completions.create({
        model: this.model,
        messages: [
          {
            role: 'system',
            content: 'You are an expert text analyst. Always respond with valid JSON only, no additional text or formatting.'
          },
          {
            role: 'user',
            content: prompt
          }
        ],
        temperature: 0.3,
        max_tokens: 500,
        response_format: { type: 'json_object' }
      });

      const response = completion.choices[0].message.content;
      
      try {
        const analysis = JSON.parse(response);
        console.log(`‚úÖ OpenAI analysis completed for ${analysisType}:`, analysis);
        return analysis;
      } catch (parseError) {
        console.warn('Failed to parse OpenAI response as JSON:', response);
        return this.createFallbackAnalysis(messageText, analysisType);
      }
    } catch (error) {
      console.error(`Error analyzing message with OpenAI (${analysisType}):`, error);
      
      // Handle rate limiting with exponential backoff
      if (error.code === 'rate_limit_exceeded') {
        console.log('Rate limit hit, implementing backoff...');
        await this.delay(this.retryDelay);
        this.retryDelay *= 2;
      }
      
      return this.createFallbackAnalysis(messageText, analysisType);
    }
  }

  async analyzeMessageComprehensive(messageText) {
    console.log(`üîç Starting comprehensive analysis for message: "${messageText.substring(0, 50)}..."`);

    const analyses = await Promise.all([
      this.analyzeMessage(messageText, 'sentiment'),
      this.analyzeMessage(messageText, 'toxicity'),
      this.analyzeMessage(messageText, 'engagement'),
      this.analyzeMessage(messageText, 'ai_detection'),
      this.analyzeMessage(messageText, 'quality')
    ]);

    return {
      sentiment: analyses[0],
      toxicity: analyses[1],
      engagement: analyses[2],
      ai_detection: analyses[3],
      quality: analyses[4],
      timestamp: new Date().toISOString()
    };
  }

  async analyzeMessagesBatch(messages) {
    console.log(`üîÑ Starting batch analysis of ${messages.length} messages with OpenAI`);
    const results = [];
    const batchSize = parseInt(process.env.BATCH_SIZE) || 5;

    // Process in smaller batches to avoid rate limits
    for (let i = 0; i < messages.length; i += batchSize) {
      const batch = messages.slice(i, i + batchSize);
      
      const batchPromises = batch.map(async (message) => {
        try {
          const analysis = await this.analyzeMessageComprehensive(message.content);
          return {
            messageId: message.id,
            guildId: message.guildId || message.guild_id || message.guild || null,
            analysis,
            processed: true
          };
        } catch (error) {
          console.error(`Error analyzing message ${message.id}:`, error);
          return {
            messageId: message.id,
            guildId: message.guildId || message.guild_id || message.guild || null,
            analysis: null,
            processed: false,
            error: error.message
          };
        }
      });

      const batchResults = await Promise.all(batchPromises);
      results.push(...batchResults);

      // Add delay between batches to respect rate limits
      if (i + batchSize < messages.length) {
        await this.delay(parseInt(process.env.ANALYSIS_DELAY_MS) || 100);
      }
    }

    console.log(`‚úÖ Batch analysis completed: ${results.filter(r => r.processed).length}/${results.length} messages analyzed`);
    return results;
  }

  calculateServerHealth(analysisResults) {
    const validResults = analysisResults.filter(r => r.analysis && r.processed);
    
    if (validResults.length === 0) {
      return {
        healthScore: 0.5,
        metrics: {},
        summary: 'Insufficient data for analysis'
      };
    }

    // Calculate average metrics
    const sentiments = validResults.map(r => r.analysis.sentiment?.sentiment || 0);
    const toxicities = validResults.map(r => r.analysis.toxicity?.toxicity || 0);
    const engagements = validResults.map(r => r.analysis.engagement?.engagement || 0.5);
    const aiLikelihoods = validResults.map(r => r.analysis.ai_detection?.ai_likelihood || 0);
    const qualities = validResults.map(r => r.analysis.quality?.quality_score || 0.5);

    const avgSentiment = sentiments.reduce((a, b) => a + b, 0) / sentiments.length;
    const avgToxicity = toxicities.reduce((a, b) => a + b, 0) / toxicities.length;
    const avgEngagement = engagements.reduce((a, b) => a + b, 0) / engagements.length;
    const avgAiLikelihood = aiLikelihoods.reduce((a, b) => a + b, 0) / aiLikelihoods.length;
    const avgQuality = qualities.reduce((a, b) => a + b, 0) / qualities.length;

    // Calculate health score (weighted)
    const healthScore = (
      (avgSentiment + 1) * 0.25 +  // Normalize sentiment to 0-1 scale
      (1 - avgToxicity) * 0.3 +     // Less toxicity is better
      avgEngagement * 0.2 +          // More engagement is better
      (1 - avgAiLikelihood) * 0.1 +  // Less AI content preferred
      avgQuality * 0.15              // Higher quality is better
    );

    return {
      healthScore: Math.max(0, Math.min(1, healthScore)),
      metrics: {
        avgSentiment,
        avgToxicity,
        avgEngagement,
        avgAiLikelihood,
        avgQuality,
        totalAnalyzed: validResults.length,
        engagementLevel: avgEngagement > 0.7 ? 'High' : avgEngagement > 0.4 ? 'Medium' : 'Low'
      },
      summary: `Analyzed ${validResults.length} messages with OpenAI`
    };
  }

  async analyzeCommunityHealth(messages) {
    if (!this.isInitialized) {
      await this.initClient();
    }

    if (!this.client || !this.isInitialized) {
      return this.createFallbackCommunityHealth();
    }

    try {
      // Limit messages to avoid token limits
      const limitedMessages = messages.slice(0, 15);
      const messagesText = limitedMessages
        .map(m => `${m.author || 'User'}: ${m.content}`)
        .join('\n');
      
      const prompt = ANALYSIS_PROMPTS.community_health.replace('{messages}', messagesText);
      
      const completion = await this.client.chat.completions.create({
        model: this.model,
        messages: [
          {
            role: 'system',
            content: 'You are a community health expert. Analyze the provided messages and respond with valid JSON only.'
          },
          {
            role: 'user',
            content: prompt
          }
        ],
        temperature: 0.4,
        max_tokens: 800,
        response_format: { type: 'json_object' }
      });

      const response = completion.choices[0].message.content;
      
      try {
        const analysis = JSON.parse(response);
        console.log('‚úÖ Community health analysis completed:', analysis);
        return analysis;
      } catch (parseError) {
        console.warn('Failed to parse community health response:', response);
        return this.createFallbackCommunityHealth();
      }
    } catch (error) {
      console.error('Error analyzing community health:', error);
      return this.createFallbackCommunityHealth();
    }
  }

  // Fallback analysis for when OpenAI is unavailable
  createFallbackAnalysis(messageText, analysisType) {
    const text = messageText.toLowerCase();
    
    switch (analysisType) {
      case 'sentiment':
        const positiveWords = ['good', 'great', 'awesome', 'love', 'nice', 'thanks', 'cool', 'amazing', 'excellent'];
        const negativeWords = ['bad', 'hate', 'stupid', 'worst', 'terrible', 'sucks', 'awful', 'horrible'];
        
        let sentiment = 0;
        let confidence = 0.3; // Low confidence for fallback
        
        positiveWords.forEach(word => {
          if (text.includes(word)) sentiment += 0.2;
        });
        
        negativeWords.forEach(word => {
          if (text.includes(word)) sentiment -= 0.2;
        });
        
        sentiment = Math.max(-1, Math.min(1, sentiment));
        
        return {
          sentiment,
          confidence,
          reasoning: 'Fallback keyword-based analysis (OpenAI unavailable)'
        };

      case 'toxicity':
        const toxicWords = ['stupid', 'idiot', 'hate', 'kill', 'die', 'shut up', 'dumb', 'loser'];
        let toxicity = 0;
        const categories = [];
        
        toxicWords.forEach(word => {
          if (text.includes(word)) {
            toxicity += 0.3;
            if (!categories.includes('insults')) categories.push('insults');
          }
        });
        
        return {
          toxicity: Math.min(1, toxicity),
          categories,
          reasoning: 'Fallback keyword-based analysis (OpenAI unavailable)'
        };

      case 'engagement':
        const hasQuestion = text.includes('?');
        const hasEmoji = /[\u{1F600}-\u{1F64F}]|[\u{1F300}-\u{1F5FF}]|[\u{1F680}-\u{1F6FF}]|[\u{1F1E0}-\u{1F1FF}]/u.test(messageText);
        const isLong = messageText.length > 50;
        const hasExclamation = text.includes('!');
        
        let engagement = 0.3;
        if (hasQuestion) engagement += 0.3;
        if (hasEmoji) engagement += 0.2;
        if (isLong) engagement += 0.2;
        if (hasExclamation) engagement += 0.1;
        
        return {
          engagement: Math.min(1, engagement),
          type: hasQuestion ? 'question' : 'general',
          reasoning: 'Fallback rule-based analysis (OpenAI unavailable)'
        };

      case 'ai_detection':
        // Simple AI detection based on patterns
        const aiIndicators = [];
        let aiLikelihood = 0;
        
        if (text.includes('as an ai') || text.includes('as a language model')) {
          aiLikelihood += 0.8;
          aiIndicators.push('AI self-identification');
        }
        
        if (messageText.length > 200 && text.split('.').length > 5) {
          aiLikelihood += 0.2;
          aiIndicators.push('Formal structure');
        }
        
        return {
          ai_likelihood: Math.min(1, aiLikelihood),
          indicators: aiIndicators,
          reasoning: 'Fallback pattern-based analysis (OpenAI unavailable)'
        };

      case 'quality':
        const hasProperGrammar = messageText.match(/[.!?]$/);
        const wordCount = messageText.split(/\s+/).length;
        
        let qualityScore = 0.3;
        if (hasProperGrammar) qualityScore += 0.2;
        if (wordCount > 5) qualityScore += 0.2;
        if (wordCount > 20) qualityScore += 0.3;
        
        return {
          quality_score: Math.min(1, qualityScore),
          constructiveness: Math.min(1, qualityScore * 0.8),
          indicators: ['Basic quality metrics'],
          reasoning: 'Fallback rule-based analysis (OpenAI unavailable)'
        };

      default:
        return { 
          error: 'Unknown analysis type',
          reasoning: 'Fallback analysis failed'
        };
    }
  }

  createFallbackCommunityHealth() {
    return {
      health_score: 0.5,
      positive_indicators: ['Active community engagement', 'Regular message activity'],
      concerns: ['Limited AI analysis available due to API issues'],
      recommendations: ['Verify OpenAI API configuration', 'Check API key validity']
    };
  }

  async delay(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}

// Global instance
let analysisServiceInstance = null;

export const getAnalysisService = () => {
  if (!analysisServiceInstance) {
    analysisServiceInstance = new AnalysisService();
  }
  return analysisServiceInstance;
};

export default AnalysisService; 